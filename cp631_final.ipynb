{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cMA83jienXc"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Course Server Setup\n",
        "\n",
        "#### Git clone repository or extract submitted file in home directory\n",
        "\n",
        "If you have the zip file of this project source code, just unzip at your home directory.  \n",
        "\n",
        "If you don't have the source code on hand, you can clone the source from git repository by the following command\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/reidlai/cp631-final\n",
        "```\n",
        "\n",
        "~/cp631-final will be this project root folder.\n",
        "\n",
        "\n",
        "#### Miniconda 3 setup\n",
        "\n",
        "Miniconda is a lightweight, open-source package and environment manager developed by Anaconda, Inc. It provides a simple and efficient way to install, manage, and distribute Python packages and their dependencies across multiple platforms, including Windows, macOS, and Linux. Unlike Anaconda, which includes a large collection of pre-installed scientific computing packages, Miniconda only ships the core Conda functionality, allowing users to customize their own package collections according to their specific requirements. With Miniconda, users can easily create isolated environments, switch between them, and share them with others via portable archives or cloud services. Additionally, Miniconda supports fast and parallel package installation through its mamba engine, which significantly improves the overall performance and usability of Conda. Overall, Miniconda offers a flexible and scalable solution for managing Python packages and environments, especially for data scientists, researchers, and developers who work with complex and diverse datasets and applications.\n",
        "\n",
        "To install miniconda3, start shell in your server.  For this case, I use course server mcs1.wlu.ca.\n",
        "\n",
        "```bash\n",
        "mkdir -p ~/miniconda3\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
        "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
        "rm -rf ~/miniconda3/miniconda.sh\n",
        "```\n",
        "\n",
        "Once miniconda3 installed, run the following command to populate conda environment setup script into .bash_profile\n",
        "\n",
        "```bash\n",
        "~/miniconda3/bin/conda init bash\n",
        "```\n",
        "\n",
        "#### Create conda environement\n",
        "\n",
        "Conda is a versatile tool for managing packages, dependencies, and environments for various programming languages, including Python, R, Ruby, Lua, Scala, Java, JavaScript, C/ C++, FORTRAN, and more. It is particularly popular in the fields of data science and machine learning. The conda create --name command is designed to create a new isolated environment within conda. The --name flag is followed by the name of the environment, in this case, cp631-final.\n",
        "\n",
        "\n",
        "```bash\n",
        "conda create --name cp631-final\n",
        "```\n",
        "\n",
        "#### Required packages installation by conda\n",
        "\n",
        "The conda install command is utilized to install packages in a specific conda environment, with the --name flag specifying the name of the environment.\n",
        "\n",
        "```bash\n",
        "cd ~/cp631-final # change directory to project root\n",
        "conda install --name cp631-final conda_requirements.txt\n",
        "rm ~/miniconda3/envs/cp631-final/compiler_compat/ld\n",
        "pip3 install -f pip3_requirements.txt\n",
        "```\n",
        "\n",
        "#### SSH Tunneling for remote Jupyter Notebook connection\n",
        "\n",
        "To allow local machine connecting to Jupyter Notebook server running in course server, VPN connection must be up and running.  Then you can use SSH Tunnelling to forward all traffic of port 8888 in local macine to course server.\n",
        "\n",
        "```bash\n",
        "ssh -L 8888:localhost:8888 wlai11@mcs1.wlu.ca\n",
        "```\n",
        "\n",
        "#### Start Jupyter Notebook server \n",
        "\n",
        "Once the shell has been spawn in remote server, run the following command to start jupyter notebook server with new conda environment cp631-final\n",
        "\n",
        "```bash\n",
        "conda activate cp631-final\n",
        "jupyter notebook --no-browser --port=8888\n",
        "```\n",
        "\n",
        "All traffice at port 8888 will forward to localhost port"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi1lrF4OCIXR"
      },
      "source": [
        "### Delare params dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "cMu8SC9pCIXS"
      },
      "outputs": [],
      "source": [
        "params = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk9UnL-SenXg"
      },
      "source": [
        "### Google Colab Environment Checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaiv3QLKenXh",
        "outputId": "d9fe1c4a-a69f-4914-95dc-5ed871b84404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In colab:  False\n",
            "Project root:  ./\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "params[\"in_colab\"] = 'google.colab' in sys.modules\n",
        "print(\"In colab: \", params[\"in_colab\"])\n",
        "os.environ[\"PROJECT_ROOT\"] = \"./\"\n",
        "print(\"Project root: \", os.environ[\"PROJECT_ROOT\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdmQ2Dn-CIXV"
      },
      "source": [
        "### Jupyter Notebook Environment Checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdeYy3ubCIXV",
        "outputId": "62ff6f54-dbc2-4471-a0c4-a095756a2452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in_notebook: True\n"
          ]
        }
      ],
      "source": [
        "from IPython import get_ipython\n",
        "def in_notebook():\n",
        "    try:\n",
        "        ipython_instance = get_ipython()\n",
        "        if ipython_instance is None:\n",
        "            return False\n",
        "        elif ipython_instance and 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
        "            return False\n",
        "    except ImportError:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "params[\"in_notebook\"] = in_notebook()\n",
        "print(f\"in_notebook: {params['in_notebook']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbdgrqQeenXi"
      },
      "source": [
        "### MacOS Environment Checking\n",
        "\n",
        "In this code, platform.system() returns the name of the operating system dependent module imported. The returned value is 'Darwin' for MacOS, 'Linux' for Linux, 'Windows' for Windows and so on. If the returned value is 'Darwin', it means you are using MacOS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNAu7JYienXj",
        "outputId": "edbbddd0-cac7-4896-dbfb-b817d7cdfd82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_macos: False\n",
            "is_debian: False\n",
            "is_redhat: True\n",
            "is_windows: False\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "import distro\n",
        "\n",
        "if platform.system() == 'Darwin':\n",
        "    params[\"is_macos\"] = True\n",
        "else:\n",
        "    params[\"is_macos\"] = False\n",
        "\n",
        "print(f'is_macos: {params[\"is_macos\"]}')\n",
        "\n",
        "if platform.system() == 'Linux':\n",
        "    distro_name = distro.id()\n",
        "    if 'debian' in distro_name.lower() or 'ubuntu' in distro_name.lower():\n",
        "        params[\"is_debian\"] = True\n",
        "        params[\"is_redhat\"] = False\n",
        "    elif 'centos' in distro_name.lower() or 'rhel' in distro_name.lower():\n",
        "        params[\"is_debian\"] = False\n",
        "        params[\"is_redhat\"] = True\n",
        "    else:\n",
        "        params[\"is_debian\"] = False\n",
        "        params[\"is_redhat\"] = False\n",
        "else:\n",
        "    params[\"is_debian\"] = False\n",
        "    params[\"is_redhat\"] = False\n",
        "    \n",
        "print(f'is_debian: {params[\"is_debian\"]}')\n",
        "print(f'is_redhat: {params[\"is_redhat\"]}')\n",
        "\n",
        "if platform.system() == 'Windows':\n",
        "    params[\"is_windows\"] = True\n",
        "else:\n",
        "    params[\"is_windows\"] = False\n",
        "print(f'is_windows: {params[\"is_windows\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2taQ58EOCIXX"
      },
      "source": [
        "### Check if using Ubuntu WSL 2.0 or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YyBBl0tCIXX",
        "outputId": "ad1ae364-6884-4d8b-f59a-dc43438aeeef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_wsl: False\n"
          ]
        }
      ],
      "source": [
        "def is_wsl():\n",
        "    try:\n",
        "        with open('/proc/version', 'r') as fh:\n",
        "            return 'microsoft' in fh.read().lower()\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "params[\"is_wsl\"] = is_wsl()\n",
        "print(f\"is_wsl: {params['is_wsl']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeA5CxA8enXm"
      },
      "source": [
        "### Check if MPI installed in OS\n",
        "\n",
        "Use the mpirun command to see if MPI is up and running.\n",
        "\n",
        "**Remarks**: We cannot use subprocess module to spawn os command \"mpirun\" to check because mprun will call this script in later testing stage and crash with recursive call error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5XesPBpxxj3",
        "outputId": "7b99c4fb-75b1-49b9-98de-abb86b39bdf0"
      },
      "outputs": [],
      "source": [
        "from mpi4py import MPI\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "size = comm.Get_size()\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "# if size > 0:\n",
        "#     params[\"mpi_installed\"] = True\n",
        "#     print(f'MPI installed: {params[\"mpi_installed\"]}')\n",
        "# else:\n",
        "#     params[\"mpi_installed\"] = False\n",
        "#     print(f'MPI installed: {params[\"mpi_installed\"]}')\n",
        "    # print(\"MPI is not installed or only has one process\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JZc6KX3xxj4"
      },
      "source": [
        "### Check if NVIDIA CUDA toolkit installed\n",
        "\n",
        "Use the numba command to see if CUDA toolkit works properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iHwripSxxj4",
        "outputId": "35d45f12-c32d-4230-fd88-dab110eaea8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 CUDA devices\n",
            "id 0    b'Tesla P100-PCIE-16GB'                              [SUPPORTED]\n",
            "                      Compute Capability: 6.0\n",
            "                           PCI Device ID: 0\n",
            "                              PCI Bus ID: 59\n",
            "                                    UUID: GPU-f059d201-c530-5269-8b00-0300bdfd892b\n",
            "                                Watchdog: Disabled\n",
            "             FP32/FP64 Performance Ratio: 2\n",
            "Summary:\n",
            "\t1/1 devices are supported\n",
            "CUDA installed: True\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda\n",
        "\n",
        "def is_cuda_installed():\n",
        "    try:\n",
        "        cuda.detect()\n",
        "        return True\n",
        "    except cuda.CudaSupportError:\n",
        "        return False\n",
        "\n",
        "if rank == 0:\n",
        "    params[\"cuda_installed\"] = is_cuda_installed()    \n",
        "    print(f'CUDA installed: {params[\"cuda_installed\"]}')\n",
        "\n",
        "    if not params[\"cuda_installed\"]:\n",
        "        print(\"[FATAL] CUDA is not installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7byduHsenXk"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJo0uW_uenXl"
      },
      "source": [
        "### Kaggle Authenticiation\n",
        "\n",
        "In this notebook, we will download a dataset from Kaggle. Before beginning the download process, it is necessary to ensure an account on Kaggle available. If you do not wish to sign in and would rather bypass the login prompt by uploading your kaggle.json file directly instead, then obtain it from your account settings page and save it either in the project root directory or content directory of Google Colab before starting this notebook. This way, you can quickly access any datasets without needing to log into Kaggle every time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFIkicQUenXl"
      },
      "source": [
        "### Install PyPi packages\n",
        "\n",
        "Installing PyPi packages is an essential step in this notebook. Among the mandatory packages, mpi4py and opendatasets provide crucial functionalities for data manipulation, distributed computing, and accessing large datasets. While Google Colab offers the convenience of bundled packages such as numpy, matplotlib, pandas, and seaborn, these packages still need to be installed separately in a local environment.\n",
        "\n",
        "Run the following code in shell to install all required library and packages\n",
        "\n",
        "```bash\n",
        "conda install --file requirements.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV62W2BwCIXZ"
      },
      "source": [
        "### Check CUDA Toolkit and Numba info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import subprocess\n",
        "\n",
        "# if rank == 0 and params[\"cuda_installed\"]:\n",
        "#     subprocess.run([\"nvcc\", \"--version\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWs90Df-CIXZ",
        "outputId": "5543c935-71df-4114-9e3c-5fd2b25e0b86"
      },
      "outputs": [],
      "source": [
        "# if rank == 0 and params[\"in_notebook\"] and params[\"cuda_installed\"]:\n",
        "#     subprocess.run([\"numba\", \"-s\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCDTeBW8xxj6"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "5xQvKYqIxxj6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import kaggle\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import yfinance as yf\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "if params[\"cuda_installed\"]:\n",
        "    from numba import cuda, float32\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMUStEeNxxj6"
      },
      "source": [
        "## S&P 500 Constituents Dataset Download\n",
        "\n",
        "I will first need to download S&P 500 constituents from my Kaggle repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2hlBaVNxxj6",
        "outputId": "81bcc3f9-c883-4ac6-e6dd-0e89c2f259fd"
      },
      "outputs": [],
      "source": [
        "kaggle.api.authenticate()\n",
        "kaggle.api.dataset_download_files('reidlai/s-and-p-500-constituents', path=\"s-and-p-500-constituents\", unzip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzAJlIr2enXn"
      },
      "source": [
        "## Stock Price History Download\n",
        "\n",
        "get_stock_price_history_quotes function will download individual stock price history within range between start_date and end_date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ZcNOK2scxxj6"
      },
      "outputs": [],
      "source": [
        "def get_stock_price_history_quotes(stock_symbol, start_date, end_date) -> pd.DataFrame:\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%dT%H:%M:%S\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%dT%H:%M:%S\")\n",
        "    \n",
        "    quotes_df = pd.DataFrame(columns=['symbol', 'timestamp', 'open', 'high', 'low', 'close', 'adjclose', 'volume'])\n",
        "    \n",
        "    if \".\" in stock_symbol:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        data = yf.download(stock_symbol, start=start_date, end=end_date, progress=False)\n",
        "        quotes_df['timestamp'] = data.index\n",
        "        quotes_df['open'] = data['Open']\n",
        "        quotes_df['high'] = data['High']\n",
        "        quotes_df['low'] = data['Low']\n",
        "        quotes_df['close'] = data['Close']\n",
        "        quotes_df['adjclose'] = data['Adj Close']\n",
        "        quotes_df['volume'] = data['Volume']\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    quotes_df.sort_values(by='timestamp', inplace=True)\n",
        "\n",
        "    if quotes_df.shape[0] > 0:\n",
        "        quotes_df['symbol'] = stock_symbol\n",
        "    return quotes_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDHJvgZkenXn"
      },
      "source": [
        "## Technical Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EMA\n",
        "\n",
        "As per proposal, we understand EMA is based on EMA value of T-1 day.  So there is dependency of daily record. And this is the main reason we cannot use CUDA for calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ema(values, days=12) -> np.ndarray:\n",
        "    alpha = 2 / (days + 1)\n",
        "    ema_values = np.empty_like(values)  # create an array to store all EMA values\n",
        "    ema_values[0] = values[0]  # start with the first value\n",
        "    for i in range(1, len(values)):\n",
        "        ema_values[i] = alpha * values[i] + (1 - alpha) * ema_values[i - 1]\n",
        "    return ema_values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RSI\n",
        "\n",
        "As per proposal, we understand RSI is based on value of EMA 12 and 26. So, same as ema function, there is dependency of daily records. And this is the main reason we cannot use CUDA for calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rsi(values, days=14) -> float:\n",
        "    gains = []\n",
        "    losses = []\n",
        "    for i in range(1, len(values)):\n",
        "        change = values[i] - values[i - 1]\n",
        "        if change > 0:\n",
        "            gains.append(change)\n",
        "            losses.append(0)\n",
        "        else:\n",
        "            gains.append(0)\n",
        "            losses.append(-change)\n",
        "    avg_gain = sum(gains[:days]) / days\n",
        "    avg_loss = sum(losses[:days]) / days\n",
        "    rs = avg_gain / avg_loss if avg_loss != 0 else 0\n",
        "    rsi_value = 100 - (100 / (1 + rs))\n",
        "    return rsi_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejwGjXFmxxj7"
      },
      "source": [
        "### MACD\n",
        "\n",
        "In this section, we'll define three functions - macd, macd_cuda, and macd_gpu.\n",
        "\n",
        "* macd function is a serial version to use dataframe calculating MACD\n",
        "\n",
        "* macd_cuda is CUDA kernel function which has similar logic like macd except using numpy array\n",
        "\n",
        "* macd_gpu is a wrapper function to copy data frame values into CUDA device memory and transfer back to host."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Br8Hly-uxxj7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def macd(df, short_period=12, long_period=26, signal_period=9) -> pd.DataFrame:\n",
        "\n",
        "    df[\"MACD\"] = df[\"EMA12\"] - df[\"EMA26\"]\n",
        "    return df\n",
        "\n",
        "if params[\"cuda_installed\"]:\n",
        "    @cuda.jit\n",
        "    def macd_cuda(ema12, ema26, macd):\n",
        "        i = cuda.grid(1)\n",
        "        if i < len(ema12):\n",
        "            macd[i] = ema12[i] - ema26[i]\n",
        "            \n",
        "    def macd_gpu(df, signal_period=9):\n",
        "        ema12_device = cuda.to_device(df[\"EMA12\"].values)\n",
        "        ema26_device = cuda.to_device(df[\"EMA26\"].values)\n",
        "        macd_device = cuda.to_device(np.empty_like(df[\"EMA12\"].values))\n",
        "        macd_cuda[df[\"EMA12\"].shape[0], 1](ema12_device, ema26_device, macd_device)\n",
        "        macd = macd_device.copy_to_host()\n",
        "        \n",
        "        del ema12_device\n",
        "        del ema26_device\n",
        "        del macd_device\n",
        "        \n",
        "        cuda.synchronize()\n",
        "        cuda.current_context().memory_manager.deallocations.clear()\n",
        "        \n",
        "        df[\"MACD\"] = macd\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yK1ez7PCIXf"
      },
      "source": [
        "### Read stock symbols from CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read symbols from the CSV file\n",
        "def read_symbols_from_csvfile(csvfile_path):\n",
        "    symbols = []\n",
        "    with open(csvfile_path, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        next(reader)  # Skip the header\n",
        "        for row in reader:\n",
        "            symbols.append(row[0])  # Assuming the symbol is the first column\n",
        "    return symbols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsTdN5KUCIXf"
      },
      "source": [
        "### Calculating EMA12, EMA26 and RSI for Serial and Parallel programming pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def emarsi(mode, symbols, start_date, end_date, rank, size, params):\n",
        "\n",
        "    results = pd.DataFrame()\n",
        "    # Fetch stock price history quotes using the local symbols\n",
        "    for symbol in symbols:\n",
        "\n",
        "        # Load the stock price history data into pandas DataFrame\n",
        "        stock_price_history_df = get_stock_price_history_quotes(symbol, start_date, end_date)\n",
        "        if stock_price_history_df is not None and stock_price_history_df.shape[0] > 0:\n",
        "            stock_price_history_df['EMA12'] = stock_price_history_df['close'].ewm(span=12, adjust=False).mean()\n",
        "            stock_price_history_df['EMA26'] = stock_price_history_df['close'].ewm(span=26, adjust=False).mean()\n",
        "            stock_price_history_df['RSI'] = stock_price_history_df['close'].rolling(window=14).apply(rsi, raw=True)\n",
        "            results = pd.concat([results, stock_price_history_df])\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTaod5vHCIXg"
      },
      "source": [
        "### Main Logic with Serial Programming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "dz13tH4KCIXg"
      },
      "outputs": [],
      "source": [
        "def main_serial(params):\n",
        "    # When using logging module, it crash iKernel so fallback to print method\n",
        "    print(\"*\" * 80)\n",
        "    print(\"* Serial execution\")\n",
        "    print(\"*\" * 80)\n",
        "    \n",
        "    previous_day = datetime.now() - timedelta(days=1)\n",
        "    first_day = previous_day - timedelta(days=int(params[\"numberOfDays\"]))\n",
        "\n",
        "    start_date = first_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "    end_date = previous_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "    \n",
        "    data_dir = './data'\n",
        "\n",
        "    gpu_cores = 0\n",
        "    rank = 0\n",
        "    size = 1\n",
        "    serial_fetching_stock_start_time = time.time()\n",
        "\n",
        "    print(f\"Rank: {rank}, Size: {size}\")\n",
        "\n",
        "    # Read symbols from the CSV file\n",
        "    symbols = read_symbols_from_csvfile(os.environ[\"PROJECT_ROOT\"] + \"s-and-p-500-constituents/sandp500-20240310.csv\")\n",
        "    symbols = symbols[:params[\"numberOfStocks\"]]\n",
        "\n",
        "\n",
        "    # ************** #\n",
        "    # * Core logic * #\n",
        "    # ************** #\n",
        "    results = emarsi(\"serial\", symbols, start_date, end_date, rank, size, params)\n",
        "    results = macd(results)\n",
        "\n",
        "    serial_fetching_stock_end_time = time.time()\n",
        "    print(f\"Serial fetching stock price history quotes completed in {serial_fetching_stock_end_time - serial_fetching_stock_start_time} seconds\")\n",
        "    serial_elapsedtime = serial_fetching_stock_end_time - serial_fetching_stock_start_time\n",
        "    return results, serial_elapsedtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWyqpk9fCIXg"
      },
      "source": [
        "### Main Logic with Hybrid Programming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "PQqTKjwDxxj7"
      },
      "outputs": [],
      "source": [
        "def main_hybrid(params):\n",
        "    # When using logging module, it crash iKernel so fallback to print method\n",
        "    print(\"*\" * 80)\n",
        "    print(\"* Parallel execution\")\n",
        "    print(\"*\" * 80)\n",
        "  \n",
        "    previous_day = datetime.now() - timedelta(days=1)\n",
        "    first_day = previous_day - timedelta(days=int(params[\"numberOfDays\"]))\n",
        "\n",
        "    start_date = first_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "    end_date = previous_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "    \n",
        "    data_dir = './data'\n",
        "\n",
        "    # Create a lock for each GPU\n",
        "    if params[\"cuda_installed\"]:\n",
        "\n",
        "        device = cuda.get_current_device()\n",
        "        print(f\"GPU name: {device.name.decode('utf-8')}\")\n",
        "\n",
        "        gpu_cores = len(cuda.gpus)\n",
        "        print(f\"GPU cores: {gpu_cores}\")\n",
        "\n",
        "    else:\n",
        "        print(\"CUDA is not available\")\n",
        "        gpu_cores = 0\n",
        "        \n",
        "\n",
        "    # MPI WTime\n",
        "    parallel_fetching_stock_start_time = MPI.Wtime()\n",
        "\n",
        "\n",
        "    print(f\"Rank: {rank}, Size: {size}\")\n",
        "\n",
        "    # Root process should scatter the symbols to all processes\n",
        "    if rank == 0:\n",
        "\n",
        "        # Read symbols from the CSV file\n",
        "        symbols = read_symbols_from_csvfile(os.environ[\"PROJECT_ROOT\"] + \"s-and-p-500-constituents/sandp500-20240310.csv\")\n",
        "        symbols = symbols[:params[\"numberOfStocks\"]]\n",
        "\n",
        "        # Calculate how many symbols each process should receive\n",
        "        symbols_per_process = len(symbols) // size\n",
        "        if size > 1:\n",
        "            remainder = len(symbols) % size\n",
        "            if remainder != 0 and rank < remainder:\n",
        "                symbols_per_process += 1\n",
        "\n",
        "            # Scatter symbols to all processes and each process should receive length of symbols / size blocks\n",
        "            local_symbols = [symbols[i:i + symbols_per_process] for i in range(0, len(symbols), symbols_per_process)]\n",
        "        else:\n",
        "          local_symbols = [symbols]\n",
        "\n",
        "    else:\n",
        "        local_symbols = None\n",
        "\n",
        "    if comm:\n",
        "        local_symbols = comm.scatter(local_symbols, root=0)\n",
        "\n",
        "    # ************** #\n",
        "    # * Core logic * #\n",
        "    # ************** #\n",
        "    print(f\"params: {params}\")\n",
        "\n",
        "    results = emarsi(\"parallel\", local_symbols, start_date, end_date, rank, size, params)\n",
        "    if comm and rank > 0:\n",
        "        # remote_result = comm.gather(results, root=0)\n",
        "        comm.send(results, dest=0)\n",
        "        return None, None\n",
        "\n",
        "    elif rank == 0:\n",
        "        \n",
        "        for i in range(1, size):\n",
        "            remote_results = comm.recv(source=i)\n",
        "            results = pd.concat([results, remote_results])\n",
        "            \n",
        "        if params[\"cuda_installed\"]:\n",
        "            results = macd_gpu(results)\n",
        "        else:\n",
        "            results = macd(results)\n",
        "        elapsed_time = 0.0;\n",
        "        \n",
        "        # MPI WTime\n",
        "        parallel_fetching_stock_end_time = MPI.Wtime()\n",
        "        print(f\"Parallel fetching stock price history quotes completed in {parallel_fetching_stock_end_time - parallel_fetching_stock_start_time} seconds\")\n",
        "        elapsed_time = parallel_fetching_stock_end_time - parallel_fetching_stock_start_time\n",
        "        \n",
        "        return results, elapsed_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zSFC0mZCIXg"
      },
      "source": [
        "### Core Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "3-4WlGYFCIXg",
        "outputId": "8205828a-0e9f-44f0-f7a7-bf08adeef8af"
      },
      "outputs": [],
      "source": [
        "def core_logic(row, params):\n",
        "    # Remove data directory recursively if exists\n",
        "    if os.path.exists(\"data\"):\n",
        "        os.system(\"rm -rf data\")\n",
        "    results, serial_elapsedtime = main_serial(params)\n",
        "    results.rename(columns={\n",
        "        \"EMA12\": \"EMA12_S\",\n",
        "        \"EMA26\": \"EMA26_S\", \n",
        "        \"RSI\": \"RSI_S\", \n",
        "        \"MACD\": \"MACD_S\", \n",
        "    }, inplace=True)\n",
        "    \n",
        "    temp_result, temp_elapsedtime = main_hybrid(params)\n",
        "    if temp_result is not None:\n",
        "        results[\"EMA12_P\"] = temp_result[\"EMA12\"]\n",
        "        results[\"EMA26_P\"] = temp_result[\"EMA26\"]\n",
        "        results[\"RSI_P\"] = temp_result[\"RSI\"]\n",
        "        results[\"MACD_P\"] = temp_result[\"MACD\"]\n",
        "        \n",
        "\n",
        "    if not os.path.exists(os.environ[\"PROJECT_ROOT\"] + \"outputs\"):\n",
        "        os.makedirs(os.environ[\"PROJECT_ROOT\"] + \"outputs\")\n",
        "    \n",
        "    filename = os.environ[\"PROJECT_ROOT\"] + f\"outputs/results-{size}-{params['numberOfStocks']}-{params['numberOfDays']}.csv\"\n",
        "    print(f\"filename: {filename}\")\n",
        "    \n",
        "    results.to_csv(filename, index=False)\n",
        "    print(\"Results saved to CSV file {filename}\")\n",
        "    \n",
        "    return results.shape[0], serial_elapsedtime, temp_elapsedtime\n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MainBody: Rank: 0, Size: 1\n",
            "Processing 10.0 stocks for 30.0 days\n",
            "Params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 10, 'numberOfDays': 30}\n",
            "********************************************************************************\n",
            "* Serial execution\n",
            "********************************************************************************\n",
            "Rank: 0, Size: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serial fetching stock price history quotes completed in 0.806349515914917 seconds\n",
            "********************************************************************************\n",
            "* Parallel execution\n",
            "********************************************************************************\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU cores: 1\n",
            "Rank: 0, Size: 1\n",
            "params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 10, 'numberOfDays': 30}\n",
            "Parallel fetching stock price history quotes completed in 0.8156401216983795 seconds\n",
            "filename: ./outputs/results-1-10-30.csv\n",
            "Results saved to CSV file {filename}\n",
            "Processing 50.0 stocks for 90.0 days\n",
            "Params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 50, 'numberOfDays': 90}\n",
            "********************************************************************************\n",
            "* Serial execution\n",
            "********************************************************************************\n",
            "Rank: 0, Size: 1\n",
            "Serial fetching stock price history quotes completed in 4.607102155685425 seconds\n",
            "********************************************************************************\n",
            "* Parallel execution\n",
            "********************************************************************************\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU cores: 1\n",
            "Rank: 0, Size: 1\n",
            "params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 50, 'numberOfDays': 90}\n",
            "Parallel fetching stock price history quotes completed in 4.6544328182935715 seconds\n",
            "filename: ./outputs/results-1-50-90.csv\n",
            "Results saved to CSV file {filename}\n",
            "Processing 100.0 stocks for 180.0 days\n",
            "Params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 100, 'numberOfDays': 180}\n",
            "********************************************************************************\n",
            "* Serial execution\n",
            "********************************************************************************\n",
            "Rank: 0, Size: 1\n",
            "Serial fetching stock price history quotes completed in 9.634976387023926 seconds\n",
            "********************************************************************************\n",
            "* Parallel execution\n",
            "********************************************************************************\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU cores: 1\n",
            "Rank: 0, Size: 1\n",
            "params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 100, 'numberOfDays': 180}\n",
            "Parallel fetching stock price history quotes completed in 9.28142960369587 seconds\n",
            "filename: ./outputs/results-1-100-180.csv\n",
            "Results saved to CSV file {filename}\n",
            "Processing 200.0 stocks for 365.0 days\n",
            "Params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 200, 'numberOfDays': 365}\n",
            "********************************************************************************\n",
            "* Serial execution\n",
            "********************************************************************************\n",
            "Rank: 0, Size: 1\n",
            "Serial fetching stock price history quotes completed in 20.245304107666016 seconds\n",
            "********************************************************************************\n",
            "* Parallel execution\n",
            "********************************************************************************\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU cores: 1\n",
            "Rank: 0, Size: 1\n",
            "params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 200, 'numberOfDays': 365}\n",
            "Parallel fetching stock price history quotes completed in 20.44671857357025 seconds\n",
            "filename: ./outputs/results-1-200-365.csv\n",
            "Results saved to CSV file {filename}\n",
            "Processing 400.0 stocks for 730.0 days\n",
            "Params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 400, 'numberOfDays': 730}\n",
            "********************************************************************************\n",
            "* Serial execution\n",
            "********************************************************************************\n",
            "Rank: 0, Size: 1\n",
            "Serial fetching stock price history quotes completed in 44.62608194351196 seconds\n",
            "********************************************************************************\n",
            "* Parallel execution\n",
            "********************************************************************************\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU cores: 1\n",
            "Rank: 0, Size: 1\n",
            "params: {'in_colab': False, 'in_notebook': True, 'is_macos': False, 'is_debian': False, 'is_redhat': True, 'is_windows': False, 'is_wsl': False, 'cuda_installed': True, 'numberOfStocks': 400, 'numberOfDays': 730}\n",
            "Parallel fetching stock price history quotes completed in 45.279446169734 seconds\n",
            "filename: ./outputs/results-1-400-730.csv\n",
            "Results saved to CSV file {filename}\n",
            "Saved stats to ./outputs/stats-1.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df = pd.DataFrame()\n",
        "df[\"numberOfStocks\"] = [10, 50, 100, 200, 400]\n",
        "df[\"numberOfDays\"] = [30, 90, 180, 365, 730]\n",
        "\n",
        "df[\"numberOfRows\"] = df[\"numberOfStocks\"] * df[\"numberOfDays\"]\n",
        "\n",
        "# Fill zeros\n",
        "df[\"serialElapsedTimes\"] = [0.0] * len(df)\n",
        "df[\"parallelElapsedTimes\"] = [0.0] * len(df)\n",
        "df[\"numberOfProcesses\"] = [0] * len(df)\n",
        "\n",
        "print(f\"MainBody: Rank: {rank}, Size: {size}\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    print(f\"Processing {row['numberOfStocks']} stocks for {row['numberOfDays']} days\")\n",
        "    params[\"numberOfStocks\"] = row[\"numberOfStocks\"].astype(int)\n",
        "    params[\"numberOfDays\"] = row[\"numberOfDays\"].astype(int)\n",
        "    \n",
        "    print(f\"Params: {params}\")\n",
        "    numberOfRows, serialElapsedTime, parrallelElapsedTime = core_logic(row, params)\n",
        "    df.loc[index, \"numberOfProcesses\"] = size\n",
        "    df.loc[index, \"numberOfRows\"] = numberOfRows\n",
        "    df.loc[index, \"serialElapsedTimes\"] = serialElapsedTime\n",
        "    df.loc[index, \"parallelElapsedTimes\"] = parrallelElapsedTime\n",
        "    \n",
        "    \n",
        "filename = os.environ[\"PROJECT_ROOT\"] + f\"outputs/stats-{size}.csv\"\n",
        "df.to_csv(filename, index=False)\n",
        "print(f\"Saved stats to {filename}\")\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export notebook into Python Script and Run with mpirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```bash\n",
        "mpirun -np 1 -mca opal_cuda_support 1 ~/miniconda3/envs/cp631-final/bin/python ~/cp631-final/cp631_final.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gtrQHTTenXn"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-0UYnFaenXn"
      },
      "source": [
        "## Performance Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not params[\"in_notebook\"]:\n",
        "    exit(0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
