{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cMA83jienXc"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Course Server Setup\n",
        "\n",
        "#### Git clone repository or extract submitted file in home directory\n",
        "\n",
        "If you have the zip file of this project source code, just unzip at your home directory.  \n",
        "\n",
        "If you don't have the source code on hand, you can clone the source from git repository by the following command\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/reidlai/cp631-final\n",
        "```\n",
        "\n",
        "~/cp631-final will be this project root folder.\n",
        "\n",
        "\n",
        "#### Miniconda 3 setup\n",
        "\n",
        "Miniconda is a lightweight, open-source package and environment manager developed by Anaconda, Inc. It provides a simple and efficient way to install, manage, and distribute Python packages and their dependencies across multiple platforms, including Windows, macOS, and Linux. Unlike Anaconda, which includes a large collection of pre-installed scientific computing packages, Miniconda only ships the core Conda functionality, allowing users to customize their own package collections according to their specific requirements. With Miniconda, users can easily create isolated environments, switch between them, and share them with others via portable archives or cloud services. Additionally, Miniconda supports fast and parallel package installation through its mamba engine, which significantly improves the overall performance and usability of Conda. Overall, Miniconda offers a flexible and scalable solution for managing Python packages and environments, especially for data scientists, researchers, and developers who work with complex and diverse datasets and applications.\n",
        "\n",
        "To install miniconda3, start shell in your server.  For this case, I use course server mcs1.wlu.ca.\n",
        "\n",
        "```bash\n",
        "mkdir -p ~/miniconda3\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
        "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
        "rm -rf ~/miniconda3/miniconda.sh\n",
        "```\n",
        "\n",
        "Once miniconda3 installed, run the following command to populate conda environment setup script into .bash_profile\n",
        "\n",
        "```bash\n",
        "~/miniconda3/bin/conda init bash\n",
        "```\n",
        "\n",
        "#### Create conda environement\n",
        "\n",
        "Conda is a versatile tool for managing packages, dependencies, and environments for various programming languages, including Python, R, Ruby, Lua, Scala, Java, JavaScript, C/ C++, FORTRAN, and more. It is particularly popular in the fields of data science and machine learning. The conda create --name command is designed to create a new isolated environment within conda. The --name flag is followed by the name of the environment, in this case, cp631-final.\n",
        "\n",
        "\n",
        "```bash\n",
        "conda create --name cp631-final\n",
        "```\n",
        "\n",
        "#### SSH Tunneling for remote Jupyter Notebook connection\n",
        "\n",
        "To allow local machine connecting to Jupyter Notebook server running in course server, VPN connection must be up and running.  Then you can use SSH Tunnelling to forward all traffic of port 8888 in local macine to course server.\n",
        "\n",
        "```bash\n",
        "ssh -L 8888:localhost:8888 wlai11@mcs1.wlu.ca\n",
        "```\n",
        "\n",
        "#### Start Jupyter Notebook server \n",
        "\n",
        "Once the shell has been spawn in remote server, run the following command to start jupyter notebook server with new conda environment cp631-final\n",
        "\n",
        "```bash\n",
        "conda activate cp631-final\n",
        "conda install -c conda-forge -y python=3.10 pip numba=0.55.0 numpy pandas matplotlib seaborn yfinance kaggle jupyter notebook\n",
        "pip3 install install mpi4py\n",
        "jupyter notebook --no-browser --port=8888\n",
        "```\n",
        "\n",
        "All traffice at port 8888 will forward to localhost port"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7byduHsenXk"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJo0uW_uenXl"
      },
      "source": [
        "### Kaggle Authenticiation\n",
        "\n",
        "In this notebook, we will download a dataset from Kaggle. Before beginning the download process, it is necessary to ensure an account on Kaggle available. If you do not wish to sign in and would rather bypass the login prompt by uploading your kaggle.json file directly instead, then obtain it from your account settings page and save it either in the project root directory or content directory of Google Colab before starting this notebook. This way, you can quickly access any datasets without needing to log into Kaggle every time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCDTeBW8xxj6"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5xQvKYqIxxj6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import kaggle\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import yfinance as yf\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from mpi4py import MPI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize environment and variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "comm = MPI.COMM_WORLD\n",
        "size = comm.Get_size()\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "os.environ[\"PROJECT_ROOT\"] = \"./\"\n",
        "params = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "if params.get('cuda_installed', False): \n",
        "  from numba import cuda, float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMUStEeNxxj6"
      },
      "source": [
        "## S&P 500 Constituents Dataset Download\n",
        "\n",
        "I will first need to download S&P 500 constituents from my Kaggle repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2hlBaVNxxj6",
        "outputId": "81bcc3f9-c883-4ac6-e6dd-0e89c2f259fd"
      },
      "outputs": [],
      "source": [
        "kaggle.api.authenticate()\n",
        "kaggle.api.dataset_download_files('reidlai/s-and-p-500-constituents', path=\"s-and-p-500-constituents\", unzip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzAJlIr2enXn"
      },
      "source": [
        "## Stock Price History Download\n",
        "\n",
        "get_stock_price_history_quotes function will download individual stock price history within range between start_date and end_date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZcNOK2scxxj6"
      },
      "outputs": [],
      "source": [
        "def get_stock_price_history_quotes(stock_symbol, start_date, end_date) -> pd.DataFrame:\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%dT%H:%M:%S\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%dT%H:%M:%S\")\n",
        "    \n",
        "    quotes_df = pd.DataFrame(columns=['symbol', 'timestamp', 'open', 'high', 'low', 'close', 'adjclose', 'volume'])\n",
        "    \n",
        "    if \".\" in stock_symbol:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        data = yf.download(stock_symbol, start=start_date, end=end_date, progress=False)\n",
        "        quotes_df['timestamp'] = data.index\n",
        "        quotes_df['open'] = data['Open']\n",
        "        quotes_df['high'] = data['High']\n",
        "        quotes_df['low'] = data['Low']\n",
        "        quotes_df['close'] = data['Close']\n",
        "        quotes_df['adjclose'] = data['Adj Close']\n",
        "        quotes_df['volume'] = data['Volume']\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    quotes_df.sort_values(by='timestamp', inplace=True)\n",
        "\n",
        "    if quotes_df.shape[0] > 0:\n",
        "        quotes_df['symbol'] = stock_symbol\n",
        "    return quotes_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDHJvgZkenXn"
      },
      "source": [
        "## Technical Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EMA\n",
        "\n",
        "As per proposal, we understand EMA is based on EMA value of T-1 day.  So there is dependency of daily record. And this is the main reason we cannot use CUDA for calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ema(values, days=12) -> np.ndarray:\n",
        "    alpha = 2 / (days + 1)\n",
        "    ema_values = np.empty_like(values)  # create an array to store all EMA values\n",
        "    ema_values[0] = values[0]  # start with the first value\n",
        "    for i in range(1, len(values)):\n",
        "        ema_values[i] = alpha * values[i] + (1 - alpha) * ema_values[i - 1]\n",
        "    return ema_values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RSI\n",
        "\n",
        "As per proposal, we understand RSI is based on value of EMA 12 and 26. So, same as ema function, there is dependency of daily records. And this is the main reason we cannot use CUDA for calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rsi(values, days=14) -> float:\n",
        "    gains = []\n",
        "    losses = []\n",
        "    for i in range(1, len(values)):\n",
        "        change = values[i] - values[i - 1]\n",
        "        if change > 0:\n",
        "            gains.append(change)\n",
        "            losses.append(0)\n",
        "        else:\n",
        "            gains.append(0)\n",
        "            losses.append(-change)\n",
        "    avg_gain = sum(gains[:days]) / days\n",
        "    avg_loss = sum(losses[:days]) / days\n",
        "    rs = avg_gain / avg_loss if avg_loss != 0 else 0\n",
        "    rsi_value = 100 - (100 / (1 + rs))\n",
        "    return rsi_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejwGjXFmxxj7"
      },
      "source": [
        "### MACD\n",
        "\n",
        "In this section, we'll define three functions - macd, macd_cuda, and macd_gpu.\n",
        "\n",
        "* macd function is a serial version to use dataframe calculating MACD\n",
        "\n",
        "* macd_cuda is CUDA kernel function which has similar logic like macd except using numpy array\n",
        "\n",
        "* macd_gpu is a wrapper function to copy data frame values into CUDA device memory and transfer back to host."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Br8Hly-uxxj7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def macd(df, short_period=12, long_period=26, signal_period=9) -> pd.DataFrame:\n",
        "\n",
        "    df[\"MACD\"] = df[\"EMA12\"] - df[\"EMA26\"]\n",
        "    return df\n",
        "\n",
        "if params.get(\"cuda_installed\", False):\n",
        "    @cuda.jit\n",
        "    def macd_cuda(ema12, ema26, macd):\n",
        "        i = cuda.grid(1)\n",
        "        if i < len(ema12):\n",
        "            macd[i] = ema12[i] - ema26[i]\n",
        "            \n",
        "    def macd_gpu(df, signal_period=9):\n",
        "        ema12_device = cuda.to_device(df[\"EMA12\"].values)\n",
        "        ema26_device = cuda.to_device(df[\"EMA26\"].values)\n",
        "        macd_device = cuda.to_device(np.empty_like(df[\"EMA12\"].values))\n",
        "        macd_cuda[df[\"EMA12\"].shape[0], 1](ema12_device, ema26_device, macd_device)\n",
        "        macd = macd_device.copy_to_host()\n",
        "        \n",
        "        del ema12_device\n",
        "        del ema26_device\n",
        "        del macd_device\n",
        "        \n",
        "        cuda.synchronize()\n",
        "        cuda.current_context().memory_manager.deallocations.clear()\n",
        "        \n",
        "        df[\"MACD\"] = macd\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yK1ez7PCIXf"
      },
      "source": [
        "### Read stock symbols from CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read symbols from the CSV file\n",
        "def read_symbols_from_csvfile(csvfile_path):\n",
        "    symbols = []\n",
        "    with open(csvfile_path, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        next(reader)  # Skip the header\n",
        "        for row in reader:\n",
        "            symbols.append(row[0])  # Assuming the symbol is the first column\n",
        "    return symbols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsTdN5KUCIXf"
      },
      "source": [
        "### Calculating EMA12, EMA26 and RSI for Serial and Parallel programming pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def emarsi(mode, symbols, start_date, end_date, rank, size, params):\n",
        "\n",
        "    results = pd.DataFrame()\n",
        "    # Fetch stock price history quotes using the local symbols\n",
        "    for symbol in symbols:\n",
        "\n",
        "        # Load the stock price history data into pandas DataFrame\n",
        "        stock_price_history_df = get_stock_price_history_quotes(symbol, start_date, end_date)\n",
        "        if stock_price_history_df is not None and stock_price_history_df.shape[0] > 0:\n",
        "            stock_price_history_df['EMA12'] = stock_price_history_df['close'].ewm(span=12, adjust=False).mean()\n",
        "            stock_price_history_df['EMA26'] = stock_price_history_df['close'].ewm(span=26, adjust=False).mean()\n",
        "            stock_price_history_df['RSI'] = stock_price_history_df['close'].rolling(window=14).apply(rsi, raw=True)\n",
        "            results = pd.concat([results, stock_price_history_df])\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTaod5vHCIXg"
      },
      "source": [
        "### Main Logic with Serial Programming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "dz13tH4KCIXg"
      },
      "outputs": [],
      "source": [
        "# def main_serial(params):\n",
        "#     # When using logging module, it crash iKernel so fallback to print method\n",
        "#     print(\"*\" * 80)\n",
        "#     print(\"* Serial execution\")\n",
        "#     print(\"*\" * 80)\n",
        "    \n",
        "#     previous_day = datetime.now() - timedelta(days=1)\n",
        "#     first_day = previous_day - timedelta(days=int(params[\"numberOfDays\"]))\n",
        "\n",
        "#     start_date = first_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "#     end_date = previous_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "    \n",
        "#     data_dir = './data'\n",
        "\n",
        "#     gpu_cores = 0\n",
        "#     rank = 0\n",
        "#     size = 1\n",
        "#     serial_fetching_stock_start_time = time.time()\n",
        "\n",
        "#     print(f\"Rank: {rank}, Size: {size}\")\n",
        "\n",
        "#     # Read symbols from the CSV file\n",
        "#     symbols = read_symbols_from_csvfile(os.environ[\"PROJECT_ROOT\"] + \"s-and-p-500-constituents/sandp500-20240310.csv\")\n",
        "#     symbols = symbols[:params[\"numberOfStocks\"]]\n",
        "\n",
        "\n",
        "#     # ************** #\n",
        "#     # * Core logic * #\n",
        "#     # ************** #\n",
        "#     results = emarsi(\"serial\", symbols, start_date, end_date, rank, size, params)\n",
        "#     results = macd(results)\n",
        "\n",
        "#     serial_fetching_stock_end_time = time.time()\n",
        "#     print(f\"Serial fetching stock price history quotes completed in {serial_fetching_stock_end_time - serial_fetching_stock_start_time} seconds\")\n",
        "#     serial_elapsedtime = serial_fetching_stock_end_time - serial_fetching_stock_start_time\n",
        "#     return results, serial_elapsedtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWyqpk9fCIXg"
      },
      "source": [
        "### Main Logic with Hybrid Programming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "PQqTKjwDxxj7"
      },
      "outputs": [],
      "source": [
        "# def main_hybrid(params):\n",
        "#     # When using logging module, it crash iKernel so fallback to print method\n",
        "#     print(\"*\" * 80)\n",
        "#     print(\"* Parallel execution\")\n",
        "#     print(\"*\" * 80)\n",
        "  \n",
        "#     previous_day = datetime.now() - timedelta(days=1)\n",
        "#     first_day = previous_day - timedelta(days=int(params[\"numberOfDays\"]))\n",
        "\n",
        "#     start_date = first_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "#     end_date = previous_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "    \n",
        "#     data_dir = './data'\n",
        "\n",
        "#     # Create a lock for each GPU\n",
        "#     if params[\"cuda_installed\"]:\n",
        "\n",
        "#         device = cuda.get_current_device()\n",
        "#         print(f\"GPU name: {device.name.decode('utf-8')}\")\n",
        "\n",
        "#         gpu_cores = len(cuda.gpus)\n",
        "#         print(f\"GPU cores: {gpu_cores}\")\n",
        "\n",
        "#     else:\n",
        "#         print(\"CUDA is not available\")\n",
        "#         gpu_cores = 0\n",
        "        \n",
        "\n",
        "#     # MPI WTime\n",
        "#     parallel_fetching_stock_start_time = MPI.Wtime()\n",
        "\n",
        "\n",
        "#     print(f\"Rank: {rank}, Size: {size}\")\n",
        "\n",
        "#     # Root process should scatter the symbols to all processes\n",
        "#     if rank == 0:\n",
        "\n",
        "#         # Read symbols from the CSV file\n",
        "#         symbols = read_symbols_from_csvfile(os.environ[\"PROJECT_ROOT\"] + \"s-and-p-500-constituents/sandp500-20240310.csv\")\n",
        "#         symbols = symbols[:params[\"numberOfStocks\"]]\n",
        "\n",
        "#         # Calculate how many symbols each process should receive\n",
        "#         symbols_per_process = len(symbols) // size\n",
        "#         if size > 1:\n",
        "#             remainder = len(symbols) % size\n",
        "#             if remainder != 0 and rank < remainder:\n",
        "#                 symbols_per_process += 1\n",
        "\n",
        "#             # Scatter symbols to all processes and each process should receive length of symbols / size blocks\n",
        "#             local_symbols = [symbols[i:i + symbols_per_process] for i in range(0, len(symbols), symbols_per_process)]\n",
        "#         else:\n",
        "#           local_symbols = [symbols]\n",
        "\n",
        "#     else:\n",
        "#         local_symbols = None\n",
        "\n",
        "#     if comm:\n",
        "#         local_symbols = comm.scatter(local_symbols, root=0)\n",
        "\n",
        "#     # ************** #\n",
        "#     # * Core logic * #\n",
        "#     # ************** #\n",
        "#     print(f\"params: {params}\")\n",
        "\n",
        "#     results = emarsi(\"parallel\", local_symbols, start_date, end_date, rank, size, params)\n",
        "#     if comm and rank > 0:\n",
        "#         # remote_result = comm.gather(results, root=0)\n",
        "#         comm.send(results, dest=0)\n",
        "#         return None, None\n",
        "\n",
        "#     elif rank == 0:\n",
        "        \n",
        "#         for i in range(1, size):\n",
        "#             remote_results = comm.recv(source=i)\n",
        "#             results = pd.concat([results, remote_results])\n",
        "            \n",
        "#         if params[\"cuda_installed\"]:\n",
        "#             results = macd_gpu(results)\n",
        "#         else:\n",
        "#             results = macd(results)\n",
        "#         elapsed_time = 0.0;\n",
        "        \n",
        "#         # MPI WTime\n",
        "#         parallel_fetching_stock_end_time = MPI.Wtime()\n",
        "#         print(f\"Parallel fetching stock price history quotes completed in {parallel_fetching_stock_end_time - parallel_fetching_stock_start_time} seconds\")\n",
        "#         elapsed_time = parallel_fetching_stock_end_time - parallel_fetching_stock_start_time\n",
        "        \n",
        "#         return results, elapsed_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zSFC0mZCIXg"
      },
      "source": [
        "### Core Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "3-4WlGYFCIXg",
        "outputId": "8205828a-0e9f-44f0-f7a7-bf08adeef8af"
      },
      "outputs": [],
      "source": [
        "# def core_logic(row, params):\n",
        "#     # Remove data directory recursively if exists\n",
        "#     if os.path.exists(\"data\"):\n",
        "#         os.system(\"rm -rf data\")\n",
        "    # results, serial_elapsedtime = main_serial(params)\n",
        "    # results.rename(columns={\n",
        "    #     \"EMA12\": \"EMA12_S\",\n",
        "    #     \"EMA26\": \"EMA26_S\", \n",
        "    #     \"RSI\": \"RSI_S\", \n",
        "    #     \"MACD\": \"MACD_S\", \n",
        "    # }, inplace=True)\n",
        "    \n",
        "    # temp_result, temp_elapsedtime = main_hybrid(params)\n",
        "    # if temp_result is not None:\n",
        "    #     results[\"EMA12_P\"] = temp_result[\"EMA12\"]\n",
        "    #     results[\"EMA26_P\"] = temp_result[\"EMA26\"]\n",
        "    #     results[\"RSI_P\"] = temp_result[\"RSI\"]\n",
        "    #     results[\"MACD_P\"] = temp_result[\"MACD\"]\n",
        "        \n",
        "\n",
        "    # if not os.path.exists(os.environ[\"PROJECT_ROOT\"] + \"outputs\"):\n",
        "    #     os.makedirs(os.environ[\"PROJECT_ROOT\"] + \"outputs\")\n",
        "    \n",
        "    # filename = os.environ[\"PROJECT_ROOT\"] + f\"outputs/results-{size}-{params['numberOfStocks']}-{params['numberOfDays']}.csv\"\n",
        "    # print(f\"filename: {filename}\")\n",
        "    \n",
        "    # results.to_csv(filename, index=False)\n",
        "    # print(\"Results saved to CSV file {filename}\")\n",
        "    \n",
        "    # return results.shape[0], serial_elapsedtime, temp_elapsedtime\n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank: 0, Size: 1\n",
            "MainBody: Rank: 0, Size: 1\n",
            "Processing 10.0 stocks for 30.0 days\n",
            "   symbol  timestamp  open  high  low  close  adjclose  volume  EMA12  EMA26  \\\n",
            "0       A 2024-02-29   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "1       A 2024-03-01   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "2       A 2024-03-04   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "3       A 2024-03-05   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "4       A 2024-03-06   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "..    ...        ...   ...   ...  ...    ...       ...     ...    ...    ...   \n",
            "16    ADI 2024-03-22   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "17    ADI 2024-03-25   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "18    ADI 2024-03-26   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "19    ADI 2024-03-27   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "20    ADI 2024-03-28   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "\n",
            "    RSI  \n",
            "0   NaN  \n",
            "1   NaN  \n",
            "2   NaN  \n",
            "3   NaN  \n",
            "4   NaN  \n",
            "..  ...  \n",
            "16  NaN  \n",
            "17  NaN  \n",
            "18  NaN  \n",
            "19  NaN  \n",
            "20  NaN  \n",
            "\n",
            "[210 rows x 11 columns]\n",
            "Processing 50.0 stocks for 90.0 days\n",
            "   symbol  timestamp  open  high  low  close  adjclose  volume  EMA12  EMA26  \\\n",
            "0       A 2024-01-02   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "1       A 2024-01-03   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "2       A 2024-01-04   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "3       A 2024-01-05   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "4       A 2024-01-08   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "..    ...        ...   ...   ...  ...    ...       ...     ...    ...    ...   \n",
            "56    AZO 2024-03-22   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "57    AZO 2024-03-25   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "58    AZO 2024-03-26   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "59    AZO 2024-03-27   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "60    AZO 2024-03-28   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "\n",
            "    RSI  \n",
            "0   NaN  \n",
            "1   NaN  \n",
            "2   NaN  \n",
            "3   NaN  \n",
            "4   NaN  \n",
            "..  ...  \n",
            "56  NaN  \n",
            "57  NaN  \n",
            "58  NaN  \n",
            "59  NaN  \n",
            "60  NaN  \n",
            "\n",
            "[3050 rows x 11 columns]\n",
            "Processing 100.0 stocks for 180.0 days\n",
            "    symbol  timestamp  open  high  low  close  adjclose  volume  EMA12  EMA26  \\\n",
            "0        A 2023-10-02   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "1        A 2023-10-03   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "2        A 2023-10-04   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "3        A 2023-10-05   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "4        A 2023-10-06   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "..     ...        ...   ...   ...  ...    ...       ...     ...    ...    ...   \n",
            "119  CMCSA 2024-03-22   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "120  CMCSA 2024-03-25   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "121  CMCSA 2024-03-26   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "122  CMCSA 2024-03-27   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "123  CMCSA 2024-03-28   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "\n",
            "     RSI  \n",
            "0    NaN  \n",
            "1    NaN  \n",
            "2    NaN  \n",
            "3    NaN  \n",
            "4    NaN  \n",
            "..   ...  \n",
            "119  NaN  \n",
            "120  NaN  \n",
            "121  NaN  \n",
            "122  NaN  \n",
            "123  NaN  \n",
            "\n",
            "[12152 rows x 11 columns]\n",
            "Processing 200.0 stocks for 365.0 days\n",
            "    symbol  timestamp  open  high  low  close  adjclose  volume  EMA12  EMA26  \\\n",
            "0        A 2023-03-31   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "1        A 2023-04-03   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "2        A 2023-04-04   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "3        A 2023-04-05   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "4        A 2023-04-06   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "..     ...        ...   ...   ...  ...    ...       ...     ...    ...    ...   \n",
            "245   GEHC 2024-03-22   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "246   GEHC 2024-03-25   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "247   GEHC 2024-03-26   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "248   GEHC 2024-03-27   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "249   GEHC 2024-03-28   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "\n",
            "     RSI  \n",
            "0    NaN  \n",
            "1    NaN  \n",
            "2    NaN  \n",
            "3    NaN  \n",
            "4    NaN  \n",
            "..   ...  \n",
            "245  NaN  \n",
            "246  NaN  \n",
            "247  NaN  \n",
            "248  NaN  \n",
            "249  NaN  \n",
            "\n",
            "[49500 rows x 11 columns]\n",
            "Processing 400.0 stocks for 730.0 days\n",
            "    symbol  timestamp  open  high  low  close  adjclose  volume  EMA12  EMA26  \\\n",
            "0        A 2022-03-31   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "1        A 2022-04-01   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "2        A 2022-04-04   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "3        A 2022-04-05   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "4        A 2022-04-06   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "..     ...        ...   ...   ...  ...    ...       ...     ...    ...    ...   \n",
            "496    ROK 2024-03-22   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "497    ROK 2024-03-25   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "498    ROK 2024-03-26   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "499    ROK 2024-03-27   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "500    ROK 2024-03-28   NaN   NaN  NaN    NaN       NaN     NaN    NaN    NaN   \n",
            "\n",
            "     RSI  \n",
            "0    NaN  \n",
            "1    NaN  \n",
            "2    NaN  \n",
            "3    NaN  \n",
            "4    NaN  \n",
            "..   ...  \n",
            "496  NaN  \n",
            "497  NaN  \n",
            "498  NaN  \n",
            "499  NaN  \n",
            "500  NaN  \n",
            "\n",
            "[198945 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Rank: {rank}, Size: {size}\")\n",
        "local_symbols = []\n",
        "\n",
        "if rank == 0:\n",
        "    df = pd.DataFrame()\n",
        "    df[\"numberOfStocks\"] = [10, 50, 100, 200, 400]\n",
        "    df[\"numberOfDays\"] = [30, 90, 180, 365, 730]\n",
        "\n",
        "    df[\"numberOfRows\"] = df[\"numberOfStocks\"] * df[\"numberOfDays\"]\n",
        "\n",
        "    # Fill zeros\n",
        "    df[\"serialElapsedTimes\"] = [0.0] * len(df)\n",
        "    df[\"parallelElapsedTimes\"] = [0.0] * len(df)\n",
        "    df[\"numberOfProcesses\"] = [0] * len(df)\n",
        "\n",
        "    print(f\"MainBody: Rank: {rank}, Size: {size}\")\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        print(f\"Processing {row['numberOfStocks']} stocks for {row['numberOfDays']} days\")\n",
        "        params[\"numberOfStocks\"] = row[\"numberOfStocks\"].astype(int)\n",
        "        params[\"numberOfDays\"] = row[\"numberOfDays\"].astype(int)\n",
        "    \n",
        "    \n",
        "        previous_day = datetime.now() - timedelta(days=1)\n",
        "        end_date = previous_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "        first_day = previous_day - timedelta(days=int(params[\"numberOfDays\"]))\n",
        "        start_date = first_day.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "    \n",
        "        data_dir = './data'\n",
        "        \n",
        "        parallel_fetching_stock_start_time = MPI.Wtime()\n",
        "        \n",
        "        # Scatter symbols to all processes\n",
        "\n",
        "        symbols = read_symbols_from_csvfile(os.environ[\"PROJECT_ROOT\"] + \"s-and-p-500-constituents/sandp500-20240310.csv\")\n",
        "        symbols = symbols[:row[\"numberOfStocks\"].astype(int)]\n",
        "        symbols_per_process = len(symbols) // size\n",
        "        if size > 1:\n",
        "            remainder = len(symbols) % size\n",
        "            if remainder != 0 and rank < remainder:\n",
        "                symbols_per_process += 1\n",
        "\n",
        "            # Scatter symbols to all processes and each process should receive length of symbols / size blocks\n",
        "            local_symbols = [symbols[i:i + symbols_per_process] for i in range(0, len(symbols), symbols_per_process)]\n",
        "        else:\n",
        "            local_symbols = [symbols]\n",
        "\n",
        "        local_symbols = comm.scatter(local_symbols, root=0)\n",
        "        \n",
        "        results = emarsi(\"parallel\", local_symbols, start_date, end_date, rank, size, params)\n",
        "        print(results)\n",
        "        \n",
        "        # df.loc[index, \"numberOfProcesses\"] = size\n",
        "        # df.loc[index, \"numberOfRows\"] = numberOfRows\n",
        "        # df.loc[index, \"serialElapsedTimes\"] = serialElapsedTime\n",
        "        # df.loc[index, \"parallelElapsedTimes\"] = parrallelElapsedTime\n",
        "    \n",
        "    \n",
        "# filename = os.environ[\"PROJECT_ROOT\"] + f\"outputs/stats-{size}.csv\"\n",
        "# df.to_csv(filename, index=False)\n",
        "# print(f\"Saved stats to {filename}\")\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export notebook into Python Script and Run with mpirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```bash\n",
        "mpirun -np 1 -mca opal_cuda_support 1 ~/miniconda3/envs/cp631-final/bin/python ~/cp631-final/cp631_final.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gtrQHTTenXn"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-0UYnFaenXn"
      },
      "source": [
        "## Performance Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not params[\"in_notebook\"]:\n",
        "    exit(0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
